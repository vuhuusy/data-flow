{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import thư viện và khởi tạo SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đọc các files từ HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn tới log_activity parquet \n",
    "log_path = \"hdfs://namenode:9000/raw_zone/fact/activity\"\n",
    "# Đường dẫn tới file danh_sach_sv_de.csv\n",
    "list_path = \"hdfs://namenode:9000/raw_zone/vdt2024/data_engineering/danh_sach_sv_de.csv\"\n",
    "\n",
    "try:\n",
    "    logDF = spark.read \\\n",
    "                .format(\"parquet\") \\\n",
    "                .load(log_path)\n",
    "except Exception as e:\n",
    "    print(f\"Error reading parquet files: {e}\")\n",
    "    \n",
    "try:\n",
    "    listDF = spark.read \\\n",
    "                .format(\"csv\") \\\n",
    "                .option(\"header\", \"false\") \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .load(list_path)\n",
    "except Exception as e:\n",
    "    print(f\"Error reading csv file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logDF.printSchema()\n",
    "listDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đổi tên cột"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "listDF = listDF.withColumnRenamed(\"_c0\", \"student_code\") \\\n",
    "                        .withColumnRenamed(\"_c1\", \"student_name\")\n",
    "listDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuyển cột timestamp thành dạng 'yyyyMMdd' và chuyển tên cột thành date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logDF = logDF.withColumn(\"timestamp\", date_format(to_date(col(\"timestamp\"), \"M/d/yyyy\"), \"yyyyMMdd\")) \\\n",
    "                .withColumnRenamed(\"timestamp\", \"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join hai DF đã được xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedDF = logDF.join(listDF, \"student_code\", \"inner\")\n",
    "joinedDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xem schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giải bài toán bằng Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedDF.createOrReplaceTempView(\"student_activity\")\n",
    "\n",
    "result_sql = spark.sql(\"SELECT \\\n",
    "                        date \\\n",
    "                        , student_code \\\n",
    "                        , student_name \\\n",
    "                        , activity \\\n",
    "                        , SUM(numberOfFile) AS totalFile \\\n",
    "                  FROM student_activity \\\n",
    "                  GROUP BY date, activity, student_code, student_name \\\n",
    "                  ORDER BY student_code, date, activity ASC\")\n",
    "result_sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giải bài toán bằng Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = joinedDF.groupBy(\"date\", \"student_code\", \"student_name\", \"activity\") \\\n",
    "              .agg(sum(\"numberOfFile\").alias(\"totalFile\")) \\\n",
    "              .orderBy(col(\"student_code\"), col(\"date\").asc(), col(\"activity\"))\n",
    "\n",
    "result_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lưu lại file vào HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.repartition(1) \\\n",
    "            .write \\\n",
    "            .csv(\"hdfs://namenode:9000/gold_zone/asignments/result/38_Vu_Huu_Sy\", \n",
    "                 header=True, \n",
    "                 mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

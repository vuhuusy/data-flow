{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This notebook shows how to connect Jupyter notebooks to a Spark Cluster, read a local CSV and store it to Hadoop as partitioned parquet files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connection to Spark Cluster\n",
    "\n",
    "To connect to the Spark cluster, create a SparkSession object with the following params:\n",
    "\n",
    "+ **appName:** application name displayed at the [Spark Master Web UI](http://localhost:8080/);\n",
    "+ **master:** Spark Master URL, same used by Spark Workers;\n",
    "+ **spark.executor.memory:** must be less than or equals to docker compose SPARK_WORKER_MEMORY config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/03 16:45:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"pyspark-notebook\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Store Data\n",
    "We will now load data from a local CSV and store it to Hadoop partitioned by column.\n",
    "Afterward you can access Hadoop UI to explore the saved parquet files.\n",
    "Access Hadoop UI on 'http://localhost:9870' (Utilities -> Browse the files system )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "import time    \n",
    "epochNow = int(time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đọc File từ HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|field1| field2|field3|   field4|\n",
      "+------+-------+------+---------+\n",
      "|    31|  write|     9|6/13/2024|\n",
      "|    11|  write|     7|6/11/2024|\n",
      "|    37|   read|     8|6/10/2024|\n",
      "|     8|   read|     6|6/15/2024|\n",
      "|    38|execute|     9|6/11/2024|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---+-----------------+\n",
      "|_c0|              _c1|\n",
      "+---+-----------------+\n",
      "|  1|       Mai Đức An|\n",
      "|  2|   Nguyễn Mai Anh|\n",
      "|  3|Ngô Ngọc Tuấn Anh|\n",
      "|  4|   Trần Trung Anh|\n",
      "|  5|    Trần Ngọc Bảo|\n",
      "+---+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_path = \"hdfs://namenode:9000/raw_zone/fact/activity\"\n",
    "list_path = \"hdfs://namenode:9000/raw_zone/vdt2024/data_engineering/danh_sach_sv_de.csv\"\n",
    "\n",
    "try:\n",
    "    logDF = spark.read.parquet(log_path)\n",
    "    \n",
    "    # Hiển thị một vài dòng dữ liệu\n",
    "    logDF.show(5)\n",
    "except Exception as e:\n",
    "    print(f\"Error reading parquet files: {e}\")\n",
    "    \n",
    "try:\n",
    "    listDF = spark.read \\\n",
    "                .format(\"csv\") \\\n",
    "                .option(\"header\", \"false\") \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .load(list_path)\n",
    "    # Hiển thị một vài dòng dữ liệu\n",
    "    listDF.show(5)\n",
    "except Exception as e:\n",
    "    print(f\"Error reading csv file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đổi tên cột"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "listDF = listDF.withColumnRenamed(\"_c0\", \"student_code\") \\\n",
    "                        .withColumnRenamed(\"_c1\", \"name\")\n",
    "\n",
    "logDF = logDF.withColumnRenamed(\"field1\", \"student_code\") \\\n",
    "                        .withColumnRenamed(\"field2\", \"activity\") \\\n",
    "                        .withColumnRenamed(\"field3\", \"numberOfFile\") \\\n",
    "                        .withColumnRenamed(\"field4\", \"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- student_code: integer (nullable = true)\n",
      " |-- activity: string (nullable = true)\n",
      " |-- numberOfFile: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuyển cột timestamp thành dạng 'yyyyMMdd' và chuyển tên cột thành date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logDF = logDF.withColumn(\"timestamp\", F.date_format(F.to_date(F.col(\"timestamp\"), \"M/d/yyyy\"), \"yyyyMMdd\")) \\\n",
    "                .withColumnRenamed(\"timestamp\", \"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kiểm tra sau khi rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+\n",
      "|student_code|             name|\n",
      "+------------+-----------------+\n",
      "|           1|       Mai Đức An|\n",
      "|           2|   Nguyễn Mai Anh|\n",
      "|           3|Ngô Ngọc Tuấn Anh|\n",
      "|           4|   Trần Trung Anh|\n",
      "|           5|    Trần Ngọc Bảo|\n",
      "+------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------+--------+------------+--------+\n",
      "|student_code|activity|numberOfFile|    date|\n",
      "+------------+--------+------------+--------+\n",
      "|          31|   write|           9|20240613|\n",
      "|          11|   write|           7|20240611|\n",
      "|          37|    read|           8|20240610|\n",
      "|           8|    read|           6|20240615|\n",
      "|          38| execute|           9|20240611|\n",
      "+------------+--------+------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "listDF.show(5)\n",
    "\n",
    "logDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join hai DF đã được xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------------+--------+-----------------+\n",
      "|student_code|activity|numberOfFile|    date|             name|\n",
      "+------------+--------+------------+--------+-----------------+\n",
      "|           1|    read|           5|20240613|       Mai Đức An|\n",
      "|           1| execute|           3|20240611|       Mai Đức An|\n",
      "|           1|   write|           6|20240610|       Mai Đức An|\n",
      "|           1| execute|          10|20240612|       Mai Đức An|\n",
      "|           1|    read|           8|20240610|       Mai Đức An|\n",
      "|           1|    read|           5|20240611|       Mai Đức An|\n",
      "|           1|    read|           9|20240613|       Mai Đức An|\n",
      "|           1|    read|           8|20240610|       Mai Đức An|\n",
      "|           1|   write|           4|20240614|       Mai Đức An|\n",
      "|           1|   write|          10|20240613|       Mai Đức An|\n",
      "|           1|    read|           9|20240610|       Mai Đức An|\n",
      "|           1|    read|           7|20240615|       Mai Đức An|\n",
      "|           1|    read|           6|20240611|       Mai Đức An|\n",
      "|           2|   write|           9|20240612|   Nguyễn Mai Anh|\n",
      "|           2|   write|           1|20240611|   Nguyễn Mai Anh|\n",
      "|           2|    read|           3|20240613|   Nguyễn Mai Anh|\n",
      "|           2| execute|           1|20240612|   Nguyễn Mai Anh|\n",
      "|           2|   write|           2|20240615|   Nguyễn Mai Anh|\n",
      "|           2|   write|          10|20240612|   Nguyễn Mai Anh|\n",
      "|           3| execute|           1|20240612|Ngô Ngọc Tuấn Anh|\n",
      "+------------+--------+------------+--------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinedDF = logDF.join(listDF, \"student_code\", \"inner\")\n",
    "joinedDF.orderBy(\"student_code\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xem schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- student_code: integer (nullable = true)\n",
      " |-- activity: string (nullable = true)\n",
      " |-- numberOfFile: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinedDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------------+--------+-----------------+\n",
      "|student_code|activity|numberOfFile|    date|             name|\n",
      "+------------+--------+------------+--------+-----------------+\n",
      "|           1|    read|           8|20240610|       Mai Đức An|\n",
      "|           1|    read|           8|20240610|       Mai Đức An|\n",
      "|           1|    read|           9|20240610|       Mai Đức An|\n",
      "|           1|   write|           6|20240610|       Mai Đức An|\n",
      "|           1| execute|           3|20240611|       Mai Đức An|\n",
      "|           1|    read|           5|20240611|       Mai Đức An|\n",
      "|           1|    read|           6|20240611|       Mai Đức An|\n",
      "|           1| execute|          10|20240612|       Mai Đức An|\n",
      "|           1|    read|           9|20240613|       Mai Đức An|\n",
      "|           1|    read|           5|20240613|       Mai Đức An|\n",
      "|           1|   write|          10|20240613|       Mai Đức An|\n",
      "|           1|   write|           4|20240614|       Mai Đức An|\n",
      "|           1|    read|           7|20240615|       Mai Đức An|\n",
      "|           2|   write|           1|20240611|   Nguyễn Mai Anh|\n",
      "|           2| execute|           1|20240612|   Nguyễn Mai Anh|\n",
      "|           2|   write|           9|20240612|   Nguyễn Mai Anh|\n",
      "|           2|   write|          10|20240612|   Nguyễn Mai Anh|\n",
      "|           2|    read|           3|20240613|   Nguyễn Mai Anh|\n",
      "|           2|   write|           2|20240615|   Nguyễn Mai Anh|\n",
      "|           3| execute|           4|20240610|Ngô Ngọc Tuấn Anh|\n",
      "+------------+--------+------------+--------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinedDF.orderBy(\"student_code\", \"date\", \"activity\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tạo bảng để sử dụng Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedDF.createOrReplaceTempView(\"student_activity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giải bài toán bằng Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-----------------+--------+---------+\n",
      "|    date|student_code|     student_name|activity|totalFile|\n",
      "+--------+------------+-----------------+--------+---------+\n",
      "|20240610|           1|       Mai Đức An|    read|       25|\n",
      "|20240610|           1|       Mai Đức An|   write|        6|\n",
      "|20240611|           1|       Mai Đức An| execute|        3|\n",
      "|20240611|           1|       Mai Đức An|    read|       11|\n",
      "|20240612|           1|       Mai Đức An| execute|       10|\n",
      "|20240613|           1|       Mai Đức An|    read|       14|\n",
      "|20240613|           1|       Mai Đức An|   write|       10|\n",
      "|20240614|           1|       Mai Đức An|   write|        4|\n",
      "|20240615|           1|       Mai Đức An|    read|        7|\n",
      "|20240611|           2|   Nguyễn Mai Anh|   write|        1|\n",
      "|20240612|           2|   Nguyễn Mai Anh| execute|        1|\n",
      "|20240612|           2|   Nguyễn Mai Anh|   write|       19|\n",
      "|20240613|           2|   Nguyễn Mai Anh|    read|        3|\n",
      "|20240615|           2|   Nguyễn Mai Anh|   write|        2|\n",
      "|20240610|           3|Ngô Ngọc Tuấn Anh| execute|        4|\n",
      "|20240610|           3|Ngô Ngọc Tuấn Anh|   write|        8|\n",
      "|20240612|           3|Ngô Ngọc Tuấn Anh| execute|        9|\n",
      "|20240612|           3|Ngô Ngọc Tuấn Anh|   write|        2|\n",
      "|20240613|           3|Ngô Ngọc Tuấn Anh| execute|        9|\n",
      "|20240613|           3|Ngô Ngọc Tuấn Anh|    read|       18|\n",
      "+--------+------------+-----------------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_sql = spark.sql(\"SELECT \\\n",
    "                        date \\\n",
    "                        , student_code \\\n",
    "                        , name AS student_name \\\n",
    "                        , activity \\\n",
    "                        , SUM(numberOfFile) AS totalFile \\\n",
    "                  FROM student_activity \\\n",
    "                  GROUP BY date, activity, student_code, name \\\n",
    "                  ORDER BY student_code, date, activity ASC\")\n",
    "result_sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giải bài toán bằng Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = joinedDF.groupBy(\"date\", \"student_code\", \"name\", \"activity\") \\\n",
    "              .agg(F.sum(\"numberOfFile\").alias(\"totalFile\")) \\\n",
    "              .orderBy(F.col(\"student_code\"), F.col(\"date\").asc(), F.col(\"activity\"))\n",
    "\n",
    "result_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.repartition(1).write.csv(\"hdfs://namenode:9000/gold_zone/asignments/result/38_Vu_Huu_Sy\", header=True, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
